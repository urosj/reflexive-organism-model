# Graph Reflexive Coherence (G‑RC) - A Single, Self‑Contained Definition  

Copyright © 2025 Uroš Jovanovič, CC BY-SA 4.0.

## Abstract

We provide a complete, unified formulation of Reflexive Coherence on a weighted graph. The definition is written as a closed reflexive loop (the same logical cycle that exists in the PDE theory) together with the *derived* notions of identity basins, sparks, seeds/front propagation and abundance, plus a set of minimal extensions that restore curvature, smooth front dynamics, analytical tractability and exact invariants.

## Core objects – the static skeleton

| Symbol                                                  | Meaning (graph → continuous analogue)                                                                                                   |
| ------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- |
| $\mathcal G^{(k)}=(V^{(k)},E^{(k)})$                    | Weighted graph at discrete time‑step $k$.  Vertices replace points $x$; edges replace infinitesimal line elements.                      |
| $C_i^{(k)}\ge0$                                         | **Coherence density** on node $i$.  Discrete analogue of the scalar field $C(x,t)$.                                                     |
| $\mathbf w^{(k)}=\{w_{ij}^{(k)}>0\}_{(i,j)\in E^{(k)}}$ | Edge conductances (weights).  They are the **metric** generated by the coherence tensor, i.e. the discrete counterpart of $g_{\mu\nu}$. |
| $\mathbf J^{(k)}=\{J_{ij}^{(k)}\}_{(i,j)\in E^{(k)}}$   | Directed flux on each edge; obeys antisymmetry $J_{ij}=-J_{ji}$.  Discrete analogue of the current $J_C^\mu$.                           |
| $\Phi_i^{(k)}$                                          | **Coherence potential** – the variational derivative of a global functional.  Plays the role of $-\delta\mathcal P/\delta C$.           |

All quantities are defined **locally**. Each node needs only its own value and the values of its immediate neighbours.

**Axiomatic vs constitutive components.** The following elements are axiomatic in Graph Reflexive Coherence:

- (i) coherence as a conserved scalar budget,
- (ii) geometry generated from coherence,
- (iii) flux as a constitutive response to coherence potential,
- (iv) identity as an emergent attractor structure, and
- (v) structural operator reflexivity (topology change).

Specific functional forms (e.g. exponential metric map, Ricci curvature term, Cheeger proxy, probabilistic front rule) constitute canonical but non-unique realizations within this class.

## Geometry from coherence – the *coherence tensor*  

For every node $i$ we build a **node‑wise second‑order tensor** that captures three physical ingredients (density, gradient, flux) exactly as in the continuous model

<span style="float:right;">(1)</span>

$$
K_i^{(k)} =
\lambda_C\, C_i^{(k)}\, I
 + \xi_C \sum_{j\in\mathcal N(i)} w_{ij}^{(k)}\,
        (C_j^{(k)}-C_i^{(k)})^{2}\,
        \mathbf e_{ij}\otimes\mathbf e_{ij}
 + \zeta_C\Bigl(\sum_{j}J_{ij}^{(k)}\Bigr)^{2} I,
$$

where:

- $I$ is the identity on the local edge‑space.  
- $\mathbf e_{ij}$ is a bookkeeping unit vector that points from $i$ to $j$.  

The three terms reproduce respectively the *density*, *gradient pressure* and *flux‑feedback* contributions of the continuous coherence tensor.

## Metric generation – edge conductances  

From the two tensors at the ends of an edge we obtain a **symmetric, strictly positive conductance**

<span style="float:right;">(2)</span>

$$
w_{ij}^{(k+1)} =
f_{\text{metric}}\bigl(K_i^{(k)},K_j^{(k)}\bigr) =
\exp\Big[-\alpha \tfrac{C_i+C_j}{2}
          -\beta \tfrac{(C_i-C_j)^{2}}{2}
          -\gamma \tfrac{J_{ij}^{2}}{2}
          -\delta \kappa^{\text{Ric}}_{ij}\Big].
$$

*The new term $\kappa^{\text{Ric}}_{ij}$ is a **discrete Ricci curvature** (Ollivier–Ricci or Forman) computed on the current graph.  It restores the missing geometric curvature of the PDE theory.*  

All parameters $\alpha,\beta,\gamma,\delta>0$ are *learnable* or can be set a‑priori.

The curvature term is optional but restores sensitivity to mesoscopic bottlenecks and anisotropy that are present in the continuum geometry but absent in purely weight-based graphs.

## Global coherence functional and node potential  

The **energy (coherence functional)** on the graph is

<span style="float:right;">(3)</span>

$$
\mathcal P^{(k)}[C] = 
\frac{\kappa_C}{2}\sum_{(i,j)\in E^{(k)}} w_{ij}^{(k)}
        \bigl(C_i^{(k)}-C_j^{(k)}\bigr)^{2} - \sum_{i\in V^{(k)}} V\bigl(C_i^{(k)}\bigr).
$$

Typical choices for the site potential $V$ are a double‑well (to create two “phases’’) or a logistic term (for bounded growth).  

The **coherence potential** is the discrete variational derivative:

<span style="float:right;">(4)</span>

$$
\Phi_i^{(k)} =
\frac{\partial\mathcal P}{\partial C_i} =
\kappa_C\sum_{j} w_{ij}^{(k)}\bigl(C_i^{(k)}-C_j^{(k)}\bigr) - V' \bigl(C_i^{(k)}\bigr).
$$

## Constitutive law – flux from geometry  

Flux on an edge follows a **gradient‑flow law** that is the exact graph analogue of $J_C = -D\,\nabla\Phi$

<span style="float:right;">(5)</span>

$$
J_{ij}^{(k)} = -\eta w_{ij}^{(k)}
          \bigl(\Phi_i^{(k)}-\Phi_j^{(k)}\bigr).
$$

Because $w_{ij}>0$, the flux always points **down** the potential, guaranteeing dissipative dynamics.

## Discrete continuity (mass balance)

The local conservation of coherence reads

<span style="float:right;">(6)</span>

$$
\frac{C_i^{(k+1)}-C_i^{(k)}}{\Delta t} = - \sum_{j\in\mathcal N(i)} J_{ij}^{(k)}.
$$

In vector form: $\mathbf C^{(k+1)} = \mathbf C^{(k)} - \Delta t\,\mathbf D\Phi^{(k)}$ with the incidence matrix hidden in the sum.

## Global invariance (exact budget preservation)

Let  

$$
B = \sum_{i\in V^{(0)}}C_i^{(0)}
$$

be the **total coherence budget** (the analogue of $\int C\,dV_g$).  
After any topology‑changing operation we enforce

<span style="float:right;">(7)</span>

$$
\sum_{i\in V^{(k+1)}} C_i^{(k+1)} = B
$$

by a **budget‑redistribution step**:

*If a new vertex $j^\star$ is created with provisional mass $\tilde C_{j^\star}$, we subtract the same amount from its parent (or distribute it proportionally among all neighbours).  If a vertex is pruned, its remaining mass is spread uniformly over the survivors.*  
All arithmetic can be performed in integer or fixed‑point format; a small “remainder’’ variable stores any fractional part and is added back on the next step, guaranteeing exact conservation up to machine precision.

## Derived structures – identities, sparks, seeds & abundance  

All update rules are required to be equivariant under graph automorphisms of the current state; identity selection therefore arises from reflexive operator change and spontaneous symmetry breaking, not from externally imposed asymmetry.

### Directed‑flux graph and identity basins  
Define a **directed edge** $i\!\to\!j$ iff $J_{ij}>0$.  The resulting digraph $\mathcal D^{(k)}$ is acyclic (except for trivial two‑node cycles that cancel out).  

- **Sink set**  

$$
\mathcal S^{(k)}=\Bigl\{s\in V^{(k)}\ \big|\ 
      J_{js}^{(k)}\ge0\ \forall j,\quad
      \sum_jJ_{js}^{(k)}>0\Bigr\}
$$  

- **Identity basin** of a sink (s) is the *attraction domain*

$$
B_{s}^{(k)} = \Big\{ i \in V^{(k)} \Big| \exists m\in\mathbb N_0 \text{ such that } (f^{(k)})^{m}(i)=s \Big\},
$$
  
  where $f^{(k)}:V^{(k)}\to V^{(k)}$ maps each node $i$ to the head of its **unique outgoing edge** (i.e. its unique successor), and $(f^{(k)})^{m}$ denotes $m$-fold composition and $f^{(k)}(i)=j\ \ \text{where} (i,j)\in E^{(k)}$ is the unique outgoing edge from $i$.
  
These basins are **exactly the consensus clusters** of a decentralised nowledge‑graph: every node receives net inward flux from its neighbours and therefore aligns with the sink’s belief.

### Spark detection (basin bifurcation)  

A spark is a *local loss of convexity* around a sink.  The continuous condition $\det \text{Hess}=0$ becomes:

1. **Restricted Laplacian** on the subgraph induced by $\{s\}\cup\mathcal N(s)$:  

$$
L^{(s)}_{ij} = 
\begin{cases}
    d_i & i=j\\
    -w_{ij} & (i,j)\in E\\
    0 & \text{otherwise}
\end{cases}.
$$

2. **Eigenvalue test** – compute the smallest non‑zero eigenvalue $\lambda_{\min}^{(s)}$.  

3. **Spark rule**  

$$
\text{if }\;\lambda_{\min}^{(s)} < -\varepsilon_{\rm spark}
\ \Longrightarrow\ \text{trigger a split of } s.
$$

Because exact eigen‑decomposition is expensive on large graphs, we replace it with an **efficient Cheeger proxy** that is mathematically equivalent up to constants:

- Compute the *conductance* of the sink’s neighbourhood:  

$$
h(s)=\frac{\sum_{i\in B_s,\ j\notin B_s} w_{ij}}{\min(\text{vol}(B_s),\text{vol}(V \setminus B_s))}.
$$  

- If $h(s) < h_{\rm thr}$ (a small threshold) we treat it as a spark.  
  This avoids repeated eigen‑solves while preserving the same bifurcation criterion.

### Soft split (smooth topology change)

When a spark fires we **do not delete the old sink instantly**. Instead we introduce an intermediate node $s^\star$ with two outgoing edges whose weights evolve over $\tau_{\rm split}$ steps:

```
t = 0 :   w_{s,s1}=w_{s,s2}=ε (tiny)
          parent mass C_s is split: 
                C_{s1}=β·C_s ,   C_{s2}=(1-β)·C_s
t → τ_split :   increase w_{s,si} gradually (e.g. geometric schedule)
               decrease w_{parent,s} accordingly
t = τ_split :  remove original node s; keep s1 and s2 as new sinks.
```

The split is thus **continuous in time**, reproducing the smooth bifurcation of the PDE picture.

### Seed / front propagation (new concepts)

A *front* consists of active nodes that have at least one inactive neighbour ($C_j=0$).  
For each such node $i$ compute its outward flux

$$
F_i^{\text{out}} = \sum_{j\notin V}\ J_{ij}.
$$

Instead of a hard deterministic threshold we could also use a **probabilistic birth rule**:

<span style="float:right;">(8)</span>

$$
p_{\rm birth}(i)=1-\exp\bigl[-\lambda F_i^{\text{out}}\bigr] .
$$

At each time step we draw a Bernoulli variable with probability $p_{\rm birth}(i)$; if it succeeds we **create a new vertex** $j^\star$ and assign

$$
C_{j^\star}^{(k+1)} = \alpha F_i^{\text{out}} \Delta t,
\qquad
C_i^{(k+1)} \leftarrow C_i^{(k+1)} - C_{j^\star}^{(k+1)},
$$

followed by the addition of edge $(i,j^\star)$ with a seed weight $w_{\rm seed}>0$.  
The exponential law makes the front advance **smoothly** and yields an effective diffusion speed that can be tuned via $\lambda$.

### Abundance  

The **abundance** at step $k$ is simply the number of identity basins:

$$
A^{(k)} = |\mathcal S^{(k)}|.
$$

A weighted version (to emphasise large basins) can be defined as

$$
\tilde A^{(k)} = \sum_{s\in\mathcal S^{(k)}} |B_s^{(k)}|^\gamma ,\qquad \gamma>0 .
$$

Because the gradient‑pressure term ($\beta>0$) amplifies edge conductances where $|C_i-C_j|$ is large, the system **self‑reinforces** gradients, which in turn drive more frequent sparks.  Hence $A^{(k)}$ is *non‑decreasing* (modulo occasional pruning of empty basins), reproducing the “ever‑generating identities’’ property of the continuous RC theory.

## Full **closed reflexive loop** – algorithmic statement  

```
INPUT:   initial graph G0 = ({i0}, ∅ ), coherence C_i0 > 0,
         parameters (α,β,γ,δ,η,κC,λ,ε_spark,…), budget B = C_i0.

FOR k = 0,1,2,… :

    #--- (a) Geometry from current state -------------------------
    for each edge (i,j) ∈ E(k):
        compute K_i , K_j by Eq.(1) using C^k and J^{k} (if any)
        w_ij ← exp[ -α·(C_i+C_j)/2  -β·(C_i-C_j)^2/2
                    -γ·J_ij^2/2 -δ·Ricci_ij ]   # Eq.(2)

    build Laplacian L(k) from {w_ij}.

    #--- (b) Coherence potential ---------------------------------
    for each node i:
        Φ_i ← κC * Σ_j w_ij (C_i - C_j)  – V'(C_i)      # Eq.(4)

    #--- (c) Flux (constitutive law) ----------------------------
    for each edge (i,j):
        J_ij ← - η * w_ij * (Φ_i - Φ_j)                # Eq.(5)

    #--- (d) Identity detection ----------------------------------
    construct directed‑flux graph D(k) from sign(J_ij).
    identify sink set S(k) and basins B_s(k).

    #--- (e) Spark detection & soft split ------------------------
    for each sink s ∈ S(k):
        compute Cheeger conductance h(s)   # cheap proxy
        if h(s) < h_thr:
            initialise soft‑split of s (τ_split steps)

    #--- (f) Front propagation (seed creation) -------------------
    for each active node i with inactive neighbours:
        F_out ← Σ_{j∉V} J_ij
        draw Bernoulli(p = 1 - exp(-λ·F_out))
        if success:
            create new vertex j*,
            C_j* ← α_seed · F_out·Δt,
            C_i   ← C_i – C_j*,
            add edge (i,j*) with weight w_seed.

    #--- (g) Pruning ---------------------------------------------
    for each node i with C_i < ε_prune and deg(i)=0:
        delete i and its incident edges
        redistribute its remaining mass uniformly over V(k)

    #--- (h) Continuity update (mass balance) --------------------
    for each node i:
        ΔC_i ← -Δt * Σ_j J_ij
        C_i   ← C_i + ΔC_i

    #--- (i) Exact budget preservation ---------------------------
    B_current ← Σ_i C_i
    if |B_current - B| > tol:
        δ = (B - B_current)/|V|
        for each i:  C_i ← C_i + δ          # exact conservation

    #--- (j) Record observables -----------------------------------
    A(k)      ← |S(k)|
    tildeA(k) ← Σ_{s∈S(k)} |B_s(k)|^γ
    optionally store {C_i}, {w_ij}, etc.

END FOR
```

Every line of the loop **depends only on quantities produced in the previous iteration**, so the system is *reflexive*: geometry $\rightarrow$ flux $\rightarrow$ coherence $\rightarrow$ geometry, exactly as in the PDE formulation.  The added modules (curvature term, soft split, probabilistic front, Cheeger spark test, budget correction) close the gaps identified earlier while preserving the original logical structure.

The ordering (a)–(i) is canonical but not unique; any ordering that preserves causal dependence and exact budget conservation defines an equivalent GRC evolution.

## Conclusion

The definition consists of:

- node coherence (eq. 1), 
- a geometry tensor $K_i$ (eq. 2), 
- conductances generated from $K_i$ (including discrete curvature) (eq. 3), 
- an energy functional $\mathcal P[C]$ giving the potential $\Phi$ (eq. 4),
- a constitutive flux law (eq. 5),
- a continuity update that conserves total coherence (eq. 6),
- exact budget preservation (eq. 7),
- probabilistic front growth (eq. 8),
- derived identity basins and spark detection (Cheeger proxy + soft split),
- an explicit algorithmic loop.  

With these definitions the **graph‑RC system implements all the essential properties of the continuous Reflexive Coherence theory** (self‑generated geometry, gradient‑flow dynamics, conserved budget, identity basins, spark‑driven bifurcations, front diffusion, ever‑increasing abundance) while being fully implementable on a discrete network that can **grow**, **shrink**, and **re‑wire** autonomously.

Any dynamical system satisfying the axioms above (regardless of specific constitutive choices) is said to belong to the **Graph Reflexive Coherence (GRC) class**.

The formulation above should be understood as a canonical, fully explicit realization of Graph Reflexive Coherence; alternative realizations that preserve the same reflexive closure, invariants, and operator reflexivity fall within the same theoretical class.

---

## Bibliography

All foundational definitions, symmetry principles, and conservation results are inherited from the ROM, Seeds, Coherence, and Reflexive Coherence papers and are not duplicated here.

- **Barabási, A.-L., & Pósfai, M.** (2016). _Network Science_. Cambridge University Press. **ISBN:** 978-1107076266

References to previous papers:

- **Jovanovic, U.** (2025). *Reflexive Organism Model*.
- **Jovanovic, U.** (2025). *Seeds of life*
- **Jovanovic, U.** (2025). *Coherence in Reflexive Organism Model*
- **Jovanovic, U.** (2025). *Reflexive Coherence*
- **Jovanovic, U.** (2025). *Reflexive Coherence: A Geometric Theory of Identity, Choice, and Abundance*
